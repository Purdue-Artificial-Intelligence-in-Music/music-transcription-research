Loading music results data...
Loaded 17438 records
Models: ['Transkun_AMT' 'CREPE_AMT' 'Sound2MIDI_Monophonic'
 'Bytedance_Piano_transcription' 'MT3' 'Basic_Pitch']
Data shape: (17438, 21)
Model colors: {'Transkun_AMT': (0.4, 0.7607843137254902, 0.6470588235294118), 'CREPE_AMT': (0.9882352941176471, 0.5529411764705883, 0.3843137254901961), 'Sound2MIDI_Monophonic': (0.5529411764705883, 0.6274509803921569, 0.796078431372549), 'Bytedance_Piano_transcription': (0.9058823529411765, 0.5411764705882353, 0.7647058823529411), 'MT3': (0.6509803921568628, 0.8470588235294118, 0.32941176470588235), 'Basic_Pitch': (1.0, 0.8509803921568627, 0.1843137254901961)}

================================================================================
COMPREHENSIVE MODEL ANALYSIS
================================================================================
Analysis Date: 2025-07-12 12:46:19
Total Dataset: 17438 files across 6 models
Models Analyzed: ['Transkun_AMT', 'CREPE_AMT', 'Sound2MIDI_Monophonic', 'Bytedance_Piano_transcription', 'MT3', 'Basic_Pitch']
Datasets: ['Maestro', 'Maestro 2004', 'Maestro 2006', 'Maestro 2008', 'Maestro 2009', 'Maestro 2011', 'Maestro 2013', 'Maestro 2014', 'Maestro 2015', 'Maestro 2017', 'Maestro 2018', 'Slakh 2100']

------------------------------------------------------------
DETAILED MODEL PERFORMANCE SUMMARY
------------------------------------------------------------

TRANSKUN_AMT:
  Files processed: 1457
  Mean F-measure: 0.8221 ± 0.1575
  Mean Precision: 0.8330 ± 0.1582
  Mean Recall: 0.8120 ± 0.1575
  Mean Runtime: 35.67 ± 28.87 seconds
  Median Runtime: 26.52 seconds
  Mean Duration: 548.5 ± 434.6 seconds
  Onset Precision: 0.9829 ± 0.1062
  Onset Recall: 0.9565 ± 0.1104
  Onset F-measure: 0.9690 ± 0.1087
  Offset Precision: 0.8886 ± 0.1058
  Offset Recall: 0.8647 ± 0.1103
  Offset F-measure: 0.8759 ± 0.1082
  Average Overlap Ratio: 0.8299 ± 0.0844
  No-Offset Precision: 0.9752 ± 0.1485
  No-Offset Recall: 0.9501 ± 0.1461
  No-Offset F-measure: 0.9622 ± 0.1468
  Performance Range (F-measure): 0.0000 to 0.9949
  Efficiency (F-measure/runtime): 0.032659

CREPE_AMT:
  Files processed: 2676
  Mean F-measure: 0.0145 ± 0.0162
  Mean Precision: 0.0139 ± 0.0144
  Mean Recall: 0.0216 ± 0.0293
  Mean Runtime: 1251.02 ± 1787.41 seconds
  Median Runtime: 169.32 seconds
  Mean Duration: 391.4 ± 344.4 seconds
  Onset Precision: 0.2483 ± 0.1163
  Onset Recall: 0.2972 ± 0.1674
  Onset F-measure: 0.2260 ± 0.0708
  Offset Precision: 0.3218 ± 0.1740
  Offset Recall: 0.3363 ± 0.1348
  Offset F-measure: 0.2753 ± 0.0758
  Average Overlap Ratio: 0.3357 ± 0.1286
  No-Offset Precision: 0.0364 ± 0.0217
  No-Offset Recall: 0.0496 ± 0.0466
  No-Offset F-measure: 0.0346 ± 0.0196
  Performance Range (F-measure): 0.0000 to 0.1378
  Efficiency (F-measure/runtime): 0.000037

SOUND2MIDI_MONOPHONIC:
  Files processed: 3382
  Mean F-measure: 0.0280 ± 0.0454
  Mean Precision: 0.0948 ± 0.0842
  Mean Recall: 0.0181 ± 0.0323
  Mean Runtime: 60.01 ± 58.12 seconds
  Median Runtime: 36.08 seconds
  Mean Duration: 412.1 ± 360.2 seconds
  Onset Precision: 0.7223 ± 0.1564
  Onset Recall: 0.1004 ± 0.1012
  Onset F-measure: 0.1623 ± 0.1444
  Offset Precision: 0.8080 ± 0.1388
  Offset Recall: 0.0969 ± 0.0897
  Offset F-measure: 0.1582 ± 0.1245
  Average Overlap Ratio: 0.7620 ± 0.1691
  No-Offset Precision: 0.2736 ± 0.1540
  No-Offset Recall: 0.0467 ± 0.0596
  No-Offset F-measure: 0.0740 ± 0.0851
  Performance Range (F-measure): 0.0000 to 0.3301
  Efficiency (F-measure/runtime): 0.000624

BYTEDANCE_PIANO_TRANSCRIPTION:
  Files processed: 1725
  Mean F-measure: 0.3784 ± 0.2601
  Mean Precision: 0.3813 ± 0.2605
  Mean Recall: 0.3758 ± 0.2598
  Mean Runtime: 269.96 ± 427.98 seconds
  Median Runtime: 77.54 seconds
  Mean Duration: 581.7 ± 469.0 seconds
  Onset Precision: 0.9884 ± 0.0535
  Onset Recall: 0.9692 ± 0.0617
  Onset F-measure: 0.9783 ± 0.0590
  Offset Precision: 0.5536 ± 0.1904
  Offset Recall: 0.5439 ± 0.1917
  Offset F-measure: 0.5484 ± 0.1912
  Average Overlap Ratio: 0.8219 ± 0.0763
  No-Offset Precision: 0.9842 ± 0.0743
  No-Offset Recall: 0.9653 ± 0.0797
  No-Offset F-measure: 0.9743 ± 0.0774
  Performance Range (F-measure): 0.0000 to 0.9813
  Efficiency (F-measure/runtime): 0.005263

MT3:
  Files processed: 4211
  Mean F-measure: 0.4304 ± 0.2437
  Mean Precision: 0.4515 ± 0.2530
  Mean Recall: 0.4129 ± 0.2375
  Mean Runtime: 228.47 ± 306.78 seconds
  Median Runtime: 83.35 seconds
  Mean Duration: 436.0 ± 377.2 seconds
  Onset Precision: 0.9776 ± 0.0825
  Onset Recall: 0.8943 ± 0.1115
  Onset F-measure: 0.9322 ± 0.0948
  Offset Precision: 0.6744 ± 0.2294
  Offset Recall: 0.6113 ± 0.2039
  Offset F-measure: 0.6397 ± 0.2128
  Average Overlap Ratio: 0.7739 ± 0.1235
  No-Offset Precision: 0.9079 ± 0.1384
  No-Offset Recall: 0.8346 ± 0.1622
  No-Offset F-measure: 0.8682 ± 0.1506
  Performance Range (F-measure): 0.0000 to 0.9767
  Efficiency (F-measure/runtime): 0.004903

BASIC_PITCH:
  Files processed: 3987
  Mean F-measure: 0.0986 ± 0.0735
  Mean Precision: 0.1197 ± 0.0858
  Mean Recall: 0.0890 ± 0.0746
  Mean Runtime: 66.75 ± 127.64 seconds
  Median Runtime: 19.60 seconds
  Mean Duration: 438.1 ± 380.4 seconds
  Onset Precision: 0.7545 ± 0.1767
  Onset Recall: 0.5584 ± 0.2143
  Onset F-measure: 0.6228 ± 0.1834
  Offset Precision: 0.6644 ± 0.1935
  Offset Recall: 0.4649 ± 0.1285
  Offset F-measure: 0.5296 ± 0.1216
  Average Overlap Ratio: 0.8182 ± 0.1329
  No-Offset Precision: 0.5666 ± 0.2351
  No-Offset Recall: 0.4401 ± 0.2539
  No-Offset F-measure: 0.4823 ± 0.2396
  Performance Range (F-measure): 0.0000 to 0.5239
  Efficiency (F-measure/runtime): 0.004166

------------------------------------------------------------
OVERALL CORRELATIONS (All Models Combined)
------------------------------------------------------------
Duration vs F-measure: 0.0212
Duration vs Precision: 0.0041
Duration vs Recall: 0.0284
Duration vs Runtime: 0.3564
Precision vs Recall: 0.9837
F-measure vs Overlap Ratio: 0.3095
F-measure vs No-Offset F-measure: 0.7230
Onset vs Offset Precision: 0.5246
Onset vs Offset Recall: 0.8162
Onset vs Offset F-measure: 0.7964
Runtime vs F-measure: -0.1415
Runtime vs Precision: -0.1692
Runtime vs Recall: -0.1243
Overlap Ratio vs Precision: 0.3324
Overlap Ratio vs Recall: 0.3019

------------------------------------------------------------
MODEL-SPECIFIC CORRELATIONS
------------------------------------------------------------

TRANSKUN_AMT Correlations:
  Duration vs F-measure: -0.0361
  Precision vs Recall: 0.9858
  F-measure vs Overlap: 0.6416
  Onset vs Offset F-measure: 0.8230
  Runtime vs F-measure: -0.0271
  Runtime vs Duration: 0.6165

CREPE_AMT Correlations:
  Duration vs F-measure: 0.1730
  Precision vs Recall: 0.6422
  F-measure vs Overlap: 0.2230
  Onset vs Offset F-measure: 0.5579
  Runtime vs F-measure: 0.3009
  Runtime vs Duration: 0.9192

SOUND2MIDI_MONOPHONIC Correlations:
  Duration vs F-measure: 0.0742
  Precision vs Recall: 0.8003
  F-measure vs Overlap: 0.0053
  Onset vs Offset F-measure: 0.9752
  Runtime vs F-measure: 0.1159
  Runtime vs Duration: 0.9006

BYTEDANCE_PIANO_TRANSCRIPTION Correlations:
  Duration vs F-measure: -0.1538
  Precision vs Recall: 0.9987
  F-measure vs Overlap: 0.3750
  Onset vs Offset F-measure: 0.2303
  Runtime vs F-measure: -0.0218
  Runtime vs Duration: 0.4565

MT3 Correlations:
  Duration vs F-measure: -0.2439
  Precision vs Recall: 0.9837
  F-measure vs Overlap: -0.1124
  Onset vs Offset F-measure: 0.0658
  Runtime vs F-measure: -0.1960
  Runtime vs Duration: 0.6065

BASIC_PITCH Correlations:
  Duration vs F-measure: -0.0681
  Precision vs Recall: 0.8096
  F-measure vs Overlap: 0.3477
  Onset vs Offset F-measure: 0.5117
  Runtime vs F-measure: -0.0708
  Runtime vs Duration: 0.7128

------------------------------------------------------------
DATASET PERFORMANCE BREAKDOWN
------------------------------------------------------------

Maestro:
  Total files: 6309
  Mean F-measure: 0.3432 ± 0.3281
  Mean Duration: 560.6 ± 441.7 seconds
  Mean Runtime: 59.41 ± 47.47 seconds
    Transkun_AMT: 1254 files, F-measure: 0.8220
    CREPE_AMT: 1 files, F-measure: 0.0262
    Sound2MIDI_Monophonic: 1271 files, F-measure: 0.0494
    Bytedance_Piano_transcription: 1271 files, F-measure: 0.3721
    MT3: 1265 files, F-measure: 0.3693
    Basic_Pitch: 1247 files, F-measure: 0.1055

Maestro 2004:
  Total files: 435
  Mean F-measure: 0.1715 ± 0.2387
  Mean Duration: 631.1 ± 441.5 seconds
  Mean Runtime: 1159.45 ± 1653.38 seconds
    Transkun_AMT: 27 files, F-measure: 0.7975
    CREPE_AMT: 131 files, F-measure: 0.0236
    Sound2MIDI_Monophonic: 27 files, F-measure: 0.0344
    MT3: 127 files, F-measure: 0.3116
    Basic_Pitch: 123 files, F-measure: 0.0771

Maestro 2006:
  Total files: 372
  Mean F-measure: 0.1511 ± 0.2056
  Mean Duration: 785.8 ± 448.5 seconds
  Mean Runtime: 1410.32 ± 1786.73 seconds
    Transkun_AMT: 14 files, F-measure: 0.8493
    CREPE_AMT: 110 files, F-measure: 0.0222
    Sound2MIDI_Monophonic: 31 files, F-measure: 0.0295
    MT3: 114 files, F-measure: 0.2876
    Basic_Pitch: 103 files, F-measure: 0.0795

Maestro 2008:
  Total files: 486
  Mean F-measure: 0.2116 ± 0.2909
  Mean Duration: 357.3 ± 190.4 seconds
  Mean Runtime: 639.51 ± 815.88 seconds
    Transkun_AMT: 46 files, F-measure: 0.8057
    CREPE_AMT: 138 files, F-measure: 0.0202
    Sound2MIDI_Monophonic: 31 files, F-measure: 0.0346
    MT3: 144 files, F-measure: 0.3652
    Basic_Pitch: 127 files, F-measure: 0.0735

Maestro 2009:
  Total files: 396
  Mean F-measure: 0.1533 ± 0.2114
  Mean Duration: 662.7 ± 468.7 seconds
  Mean Runtime: 1210.61 ± 1610.87 seconds
    Transkun_AMT: 7 files, F-measure: 0.7942
    CREPE_AMT: 122 files, F-measure: 0.0249
    Sound2MIDI_Monophonic: 24 files, F-measure: 0.0314
    MT3: 124 files, F-measure: 0.3350
    Basic_Pitch: 119 files, F-measure: 0.0823

Maestro 2011:
  Total files: 515
  Mean F-measure: 0.2065 ± 0.2852
  Mean Duration: 342.0 ± 171.5 seconds
  Mean Runtime: 652.49 ± 786.32 seconds
    Transkun_AMT: 38 files, F-measure: 0.8265
    CREPE_AMT: 158 files, F-measure: 0.0229
    Sound2MIDI_Monophonic: 24 files, F-measure: 0.0539
    MT3: 160 files, F-measure: 0.3731
    Basic_Pitch: 135 files, F-measure: 0.0764

Maestro 2013:
  Total files: 389
  Mean F-measure: 0.1846 ± 0.2414
  Mean Duration: 408.7 ± 220.0 seconds
  Mean Runtime: 748.31 ± 943.01 seconds
    Transkun_AMT: 4 files, F-measure: 0.7952
    CREPE_AMT: 113 files, F-measure: 0.0249
    Sound2MIDI_Monophonic: 28 files, F-measure: 0.0718
    MT3: 126 files, F-measure: 0.3946
    Basic_Pitch: 118 files, F-measure: 0.1194

Maestro 2014:
  Total files: 439
  Mean F-measure: 0.2120 ± 0.2372
  Mean Duration: 858.1 ± 639.5 seconds
  Mean Runtime: 1454.49 ± 1978.70 seconds
    Transkun_AMT: 9 files, F-measure: 0.8515
    CREPE_AMT: 101 files, F-measure: 0.0185
    Sound2MIDI_Monophonic: 20 files, F-measure: 0.0451
    Bytedance_Piano_transcription: 104 files, F-measure: 0.3573
    MT3: 105 files, F-measure: 0.3554
    Basic_Pitch: 100 files, F-measure: 0.0817

Maestro 2015:
  Total files: 623
  Mean F-measure: 0.2353 ± 0.2797
  Mean Duration: 393.0 ± 226.8 seconds
  Mean Runtime: 575.20 ± 766.07 seconds
    Transkun_AMT: 14 files, F-measure: 0.7778
    CREPE_AMT: 120 files, F-measure: 0.0299
    Sound2MIDI_Monophonic: 119 files, F-measure: 0.0803
    Bytedance_Piano_transcription: 124 files, F-measure: 0.4319
    MT3: 129 files, F-measure: 0.4306
    Basic_Pitch: 117 files, F-measure: 0.1150

Maestro 2017:
  Total files: 589
  Mean F-measure: 0.2738 ± 0.2979
  Mean Duration: 413.2 ± 209.6 seconds
  Mean Runtime: 681.84 ± 792.64 seconds
    Transkun_AMT: 31 files, F-measure: 0.8777
    CREPE_AMT: 130 files, F-measure: 0.0279
    Sound2MIDI_Monophonic: 28 files, F-measure: 0.0891
    Bytedance_Piano_transcription: 134 files, F-measure: 0.4283
    MT3: 139 files, F-measure: 0.4132
    Basic_Pitch: 127 files, F-measure: 0.1031

Maestro 2018:
  Total files: 456
  Mean F-measure: 0.1911 ± 0.2349
  Mean Duration: 1066.9 ± 639.7 seconds
  Mean Runtime: 1502.07 ± 2106.00 seconds
    Transkun_AMT: 13 files, F-measure: 0.8151
    CREPE_AMT: 86 files, F-measure: 0.0240
    Sound2MIDI_Monophonic: 88 files, F-measure: 0.0403
    Bytedance_Piano_transcription: 92 files, F-measure: 0.3448
    MT3: 91 files, F-measure: 0.3380
    Basic_Pitch: 86 files, F-measure: 0.0985

Slakh 2100:
  Total files: 6429
  Mean F-measure: 0.1655 ± 0.2402
  Mean Duration: 248.8 ± 59.1 seconds
  Mean Runtime: 60.97 ± 45.86 seconds
    CREPE_AMT: 1466 files, F-measure: 0.0067
    Sound2MIDI_Monophonic: 1691 files, F-measure: 0.0050
    MT3: 1687 files, F-measure: 0.5266
    Basic_Pitch: 1585 files, F-measure: 0.0991

------------------------------------------------------------
PERFORMANCE RANKINGS
------------------------------------------------------------

F MEASURE Rankings:
  1. Transkun_AMT: 0.8221
  2. MT3: 0.4304
  3. Bytedance_Piano_transcription: 0.3784
  4. Basic_Pitch: 0.0986
  5. Sound2MIDI_Monophonic: 0.0280
  6. CREPE_AMT: 0.0145

PRECISION Rankings:
  1. Transkun_AMT: 0.8330
  2. MT3: 0.4515
  3. Bytedance_Piano_transcription: 0.3813
  4. Basic_Pitch: 0.1197
  5. Sound2MIDI_Monophonic: 0.0948
  6. CREPE_AMT: 0.0139

RECALL Rankings:
  1. Transkun_AMT: 0.8120
  2. MT3: 0.4129
  3. Bytedance_Piano_transcription: 0.3758
  4. Basic_Pitch: 0.0890
  5. CREPE_AMT: 0.0216
  6. Sound2MIDI_Monophonic: 0.0181

ONSET F MEASURE Rankings:
  1. Bytedance_Piano_transcription: 0.9783
  2. Transkun_AMT: 0.9690
  3. MT3: 0.9322
  4. Basic_Pitch: 0.6228
  5. CREPE_AMT: 0.2260
  6. Sound2MIDI_Monophonic: 0.1623

OFFSET F MEASURE Rankings:
  1. Transkun_AMT: 0.8759
  2. MT3: 0.6397
  3. Bytedance_Piano_transcription: 0.5484
  4. Basic_Pitch: 0.5296
  5. CREPE_AMT: 0.2753
  6. Sound2MIDI_Monophonic: 0.1582

AVERAGE OVERLAP RATIO Rankings:
  1. Transkun_AMT: 0.8299
  2. Bytedance_Piano_transcription: 0.8219
  3. Basic_Pitch: 0.8182
  4. MT3: 0.7739
  5. Sound2MIDI_Monophonic: 0.7620
  6. CREPE_AMT: 0.3357

------------------------------------------------------------
EFFICIENCY ANALYSIS
------------------------------------------------------------
Runtime Efficiency Rankings (F-measure per second):
  1. Transkun_AMT: 0.032659 F-measure/sec (1.9595 F-measure/min)
  2. Bytedance_Piano_transcription: 0.005263 F-measure/sec (0.3158 F-measure/min)
  3. MT3: 0.004903 F-measure/sec (0.2942 F-measure/min)
  4. Basic_Pitch: 0.004166 F-measure/sec (0.2500 F-measure/min)
  5. Sound2MIDI_Monophonic: 0.000624 F-measure/sec (0.0375 F-measure/min)
  6. CREPE_AMT: 0.000037 F-measure/sec (0.0022 F-measure/min)

------------------------------------------------------------
STATISTICAL SIGNIFICANCE TESTS
------------------------------------------------------------
ANOVA F-statistic for F-measure differences: 8452.9524
ANOVA p-value: 0.000000
Significant difference between models: Yes

Pairwise t-tests between models (F-measure):
  Transkun_AMT vs CREPE_AMT: t=262.8261, p=0.000000
  Transkun_AMT vs Sound2MIDI_Monophonic: t=268.5221, p=0.000000
  Transkun_AMT vs Bytedance_Piano_transcription: t=56.8994, p=0.000000
  Transkun_AMT vs MT3: t=57.3516, p=0.000000
  Transkun_AMT vs Basic_Pitch: t=229.7220, p=0.000000
  CREPE_AMT vs Sound2MIDI_Monophonic: t=-14.6710, p=0.000000
  CREPE_AMT vs Bytedance_Piano_transcription: t=-72.1564, p=0.000000
  CREPE_AMT vs MT3: t=-88.1678, p=0.000000
  CREPE_AMT vs Basic_Pitch: t=-58.2618, p=0.000000
  Sound2MIDI_Monophonic vs Bytedance_Piano_transcription: t=-76.0976, p=0.000000
  Sound2MIDI_Monophonic vs MT3: t=-94.7189, p=0.000000
  Sound2MIDI_Monophonic vs Basic_Pitch: t=-48.5327, p=0.000000
  Bytedance_Piano_transcription vs MT3: t=-7.3209, p=0.000000
  Bytedance_Piano_transcription vs Basic_Pitch: t=62.4214, p=0.000000
  MT3 vs Basic_Pitch: t=82.5106, p=0.000000

------------------------------------------------------------
COMPLETE CORRELATION MATRIX
------------------------------------------------------------

Correlation Matrix (only values > 0.3 or < -0.3):
  duration_seconds vs runtime: 0.3564
  precision vs recall: 0.9837
  precision vs f_measure: 0.9908
  precision vs average_overlap_ratio: 0.3324
  precision vs precision_no_offset: 0.6861
  precision vs recall_no_offset: 0.6864
  precision vs f_measure_no_offset: 0.6890
  precision vs average_overlap_ratio_no_offset: 0.7839
  precision vs onset_precision: 0.6053
  precision vs onset_recall: 0.6561
  precision vs onset_f_measure: 0.6750
  precision vs offset_precision: 0.5256
  precision vs offset_recall: 0.8122
  precision vs offset_f_measure: 0.8302
  recall vs f_measure: 0.9982
  recall vs average_overlap_ratio: 0.3019
  recall vs precision_no_offset: 0.6868
  recall vs recall_no_offset: 0.7327
  recall vs f_measure_no_offset: 0.7238
  recall vs average_overlap_ratio_no_offset: 0.7421
  recall vs onset_precision: 0.5611
  recall vs onset_recall: 0.7142
  recall vs onset_f_measure: 0.7091
  recall vs offset_precision: 0.4340
  recall vs offset_recall: 0.8522
  recall vs offset_f_measure: 0.8390
  f_measure vs average_overlap_ratio: 0.3095
  f_measure vs precision_no_offset: 0.6937
  f_measure vs recall_no_offset: 0.7271
  f_measure vs f_measure_no_offset: 0.7230
  f_measure vs average_overlap_ratio_no_offset: 0.7498
  f_measure vs onset_precision: 0.5789
  f_measure vs onset_recall: 0.7063
  f_measure vs onset_f_measure: 0.7111
  f_measure vs offset_precision: 0.4592
  f_measure vs offset_recall: 0.8491
  f_measure vs offset_f_measure: 0.8484
  average_overlap_ratio vs precision_no_offset: 0.5907
  average_overlap_ratio vs recall_no_offset: 0.4828
  average_overlap_ratio vs f_measure_no_offset: 0.5060
  average_overlap_ratio vs average_overlap_ratio_no_offset: 0.7009
  average_overlap_ratio vs onset_precision: 0.7040
  average_overlap_ratio vs onset_recall: 0.4015
  average_overlap_ratio vs onset_f_measure: 0.4793
  average_overlap_ratio vs offset_precision: 0.4683
  average_overlap_ratio vs offset_f_measure: 0.3513
  average_overlap_ratio vs runtime: -0.3316
  precision_no_offset vs recall_no_offset: 0.9505
  precision_no_offset vs f_measure_no_offset: 0.9707
  precision_no_offset vs average_overlap_ratio_no_offset: 0.5848
  precision_no_offset vs onset_precision: 0.8833
  precision_no_offset vs onset_recall: 0.8836
  precision_no_offset vs onset_f_measure: 0.9383
  precision_no_offset vs offset_recall: 0.6449
  precision_no_offset vs offset_f_measure: 0.6866
  recall_no_offset vs f_measure_no_offset: 0.9953
  recall_no_offset vs average_overlap_ratio_no_offset: 0.5260
  recall_no_offset vs onset_precision: 0.7492
  recall_no_offset vs onset_recall: 0.9654
  recall_no_offset vs onset_f_measure: 0.9680
  recall_no_offset vs offset_recall: 0.7305
  recall_no_offset vs offset_f_measure: 0.7087
  f_measure_no_offset vs average_overlap_ratio_no_offset: 0.5343
  f_measure_no_offset vs onset_precision: 0.7875
  f_measure_no_offset vs onset_recall: 0.9550
  f_measure_no_offset vs onset_f_measure: 0.9770
  f_measure_no_offset vs offset_recall: 0.7222
  f_measure_no_offset vs offset_f_measure: 0.7240
  average_overlap_ratio_no_offset vs onset_precision: 0.6563
  average_overlap_ratio_no_offset vs onset_recall: 0.4607
  average_overlap_ratio_no_offset vs onset_f_measure: 0.5064
  average_overlap_ratio_no_offset vs offset_precision: 0.6758
  average_overlap_ratio_no_offset vs offset_recall: 0.5615
  average_overlap_ratio_no_offset vs offset_f_measure: 0.6204
  onset_precision vs onset_recall: 0.6483
  onset_precision vs onset_f_measure: 0.7634
  onset_precision vs offset_precision: 0.5246
  onset_precision vs offset_recall: 0.4436
  onset_precision vs offset_f_measure: 0.5687
  onset_precision vs runtime: -0.4020
  onset_recall vs onset_f_measure: 0.9715
  onset_recall vs offset_recall: 0.8162
  onset_recall vs offset_f_measure: 0.7542
  onset_f_measure vs offset_recall: 0.7849
  onset_f_measure vs offset_f_measure: 0.7964
  offset_precision vs offset_f_measure: 0.4298
  offset_precision vs runtime: -0.4642
  offset_recall vs offset_f_measure: 0.9504

------------------------------------------------------------
FIGURES SAVED
------------------------------------------------------------
1. figures/01_core_performance_analysis.png - Main performance comparisons
2. figures/02_onset_offset_analysis.png - Onset/offset detailed analysis
3. figures/03_advanced_performance_patterns.png - Advanced pattern analysis
4. figures/04_statistical_summary.png - Statistical summary and rankings

================================================================================
ANALYSIS COMPLETE!
================================================================================
