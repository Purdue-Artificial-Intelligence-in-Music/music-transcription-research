Loading music results data...
Loaded 28560 records
Models: ['MT3' 'Transkun' 'Bytedance_Piano_transcription' 'Basic_Pitch' 'MR-MT3'
 'CREPE_Pitch_Tracker' 'ReconVAT' 'Omnizart' 'Madmom']
Data shape: (28560, 21)
Model colors: {'MT3': (0.4, 0.7607843137254902, 0.6470588235294118), 'Transkun': (0.9882352941176471, 0.5529411764705883, 0.3843137254901961), 'Bytedance_Piano_transcription': (0.5529411764705883, 0.6274509803921569, 0.796078431372549), 'Basic_Pitch': (0.9058823529411765, 0.5411764705882353, 0.7647058823529411), 'MR-MT3': (0.6509803921568628, 0.8470588235294118, 0.32941176470588235), 'CREPE_Pitch_Tracker': (1.0, 0.8509803921568627, 0.1843137254901961), 'ReconVAT': (0.8980392156862745, 0.7686274509803922, 0.5803921568627451), 'Omnizart': (0.7019607843137254, 0.7019607843137254, 0.7019607843137254), 'Madmom': (0.4, 0.7607843137254902, 0.6470588235294118)}

================================================================================
COMPREHENSIVE MODEL ANALYSIS
================================================================================
Analysis Date: 2025-08-03 22:01:33
Total Dataset: 28560 files across 9 models
Models Analyzed: ['MT3', 'Transkun', 'Bytedance_Piano_transcription', 'Basic_Pitch', 'MR-MT3', 'CREPE_Pitch_Tracker', 'ReconVAT', 'Omnizart', 'Madmom']
Datasets: ['AAM', 'BiMMuDa', 'MSMD', 'POP909', 'Slakh 2100 Redux']

------------------------------------------------------------
DETAILED MODEL PERFORMANCE SUMMARY
------------------------------------------------------------

MT3:
  Files processed: 4751
  Mean F-measure: 0.3788 ± 0.2763
  Mean Precision: 0.3807 ± 0.2789
  Mean Recall: 0.3845 ± 0.2749
  Mean Runtime: 37.01 ± 34.77 seconds
  Median Runtime: 28.05 seconds
  Mean Duration: 171.2 ± 59.2 seconds
  Onset Precision: 0.8880 ± 0.1113
  Onset Recall: 0.9090 ± 0.1311
  Onset F-measure: 0.8857 ± 0.0812
  Offset Precision: 0.7353 ± 0.1530
  Offset Recall: 0.7551 ± 0.1731
  Offset F-measure: 0.7339 ± 0.1382
  Average Overlap Ratio: 0.9506 ± 0.0276
  No-Offset Precision: 0.7266 ± 0.2120
  No-Offset Recall: 0.7415 ± 0.2040
  No-Offset F-measure: 0.7252 ± 0.2015
  Performance Range (F-measure): 0.0000 to 1.0000
  Efficiency (F-measure/runtime): 0.012325

TRANSKUN:
  Files processed: 1751
  Mean F-measure: 0.6356 ± 0.1807
  Mean Precision: 0.6410 ± 0.1784
  Mean Recall: 0.6309 ± 0.1831
  Mean Runtime: 47.04 ± 16.48 seconds
  Median Runtime: 44.56 seconds
  Mean Duration: 201.0 ± 87.0 seconds
  Onset Precision: 0.9947 ± 0.0159
  Onset Recall: 0.9758 ± 0.0398
  Onset F-measure: 0.9847 ± 0.0300
  Offset Precision: 0.7438 ± 0.1203
  Offset Recall: 0.7297 ± 0.1242
  Offset F-measure: 0.7362 ± 0.1221
  Average Overlap Ratio: 0.9276 ± 0.0336
  No-Offset Precision: 0.9939 ± 0.0199
  No-Offset Recall: 0.9751 ± 0.0404
  No-Offset F-measure: 0.9839 ± 0.0308
  Performance Range (F-measure): 0.0089 to 1.0000
  Efficiency (F-measure/runtime): 0.015081

BYTEDANCE_PIANO_TRANSCRIPTION:
  Files processed: 1751
  Mean F-measure: 0.5695 ± 0.3083
  Mean Precision: 0.5887 ± 0.3056
  Mean Recall: 0.5585 ± 0.3127
  Mean Runtime: 47.57 ± 16.31 seconds
  Median Runtime: 45.59 seconds
  Mean Duration: 201.0 ± 87.0 seconds
  Onset Precision: 0.9882 ± 0.0203
  Onset Recall: 0.9319 ± 0.1219
  Onset F-measure: 0.9541 ± 0.0934
  Offset Precision: 0.7403 ± 0.1910
  Offset Recall: 0.6982 ± 0.2121
  Offset F-measure: 0.7140 ± 0.2007
  Average Overlap Ratio: 0.9378 ± 0.0308
  No-Offset Precision: 0.9829 ± 0.0260
  No-Offset Recall: 0.9273 ± 0.1243
  No-Offset F-measure: 0.9493 ± 0.0963
  Performance Range (F-measure): 0.0027 to 1.0000
  Efficiency (F-measure/runtime): 0.014539

BASIC_PITCH:
  Files processed: 4751
  Mean F-measure: 0.2331 ± 0.1328
  Mean Precision: 0.2481 ± 0.1225
  Mean Recall: 0.2325 ± 0.1511
  Mean Runtime: 27.10 ± 28.09 seconds
  Median Runtime: 9.13 seconds
  Mean Duration: 171.2 ± 59.2 seconds
  Onset Precision: 0.7660 ± 0.1111
  Onset Recall: 0.6971 ± 0.2162
  Onset F-measure: 0.7082 ± 0.1485
  Offset Precision: 0.6616 ± 0.1235
  Offset Recall: 0.5859 ± 0.1526
  Offset F-measure: 0.6011 ± 0.0981
  Average Overlap Ratio: 0.8961 ± 0.0324
  No-Offset Precision: 0.5742 ± 0.1805
  No-Offset Recall: 0.5441 ± 0.2715
  No-Offset F-measure: 0.5435 ± 0.2233
  Performance Range (F-measure): 0.0008 to 0.8293
  Efficiency (F-measure/runtime): 0.014960

MR-MT3:
  Files processed: 842
  Mean F-measure: 0.0029 ± 0.0050
  Mean Precision: 0.0028 ± 0.0048
  Mean Recall: 0.0033 ± 0.0057
  Mean Runtime: 220.55 ± 206.48 seconds
  Median Runtime: 173.86 seconds
  Mean Duration: 148.5 ± 92.2 seconds
  Onset Precision: 0.0503 ± 0.0888
  Onset Recall: 0.0563 ± 0.0946
  Onset F-measure: 0.0517 ± 0.0885
  Offset Precision: 0.5038 ± 0.1372
  Offset Recall: 0.5537 ± 0.1302
  Offset F-measure: 0.5142 ± 0.1047
  Average Overlap Ratio: 0.3571 ± 0.3708
  No-Offset Precision: 0.0078 ± 0.0114
  No-Offset Recall: 0.0093 ± 0.0144
  No-Offset F-measure: 0.0083 ± 0.0122
  Performance Range (F-measure): 0.0000 to 0.0380
  Efficiency (F-measure/runtime): 0.000016

CREPE_PITCH_TRACKER:
  Files processed: 6461
  Mean F-measure: 0.0029 ± 0.0072
  Mean Precision: 0.0032 ± 0.0079
  Mean Recall: 0.0059 ± 0.0231
  Mean Runtime: 33.76 ± 56.12 seconds
  Median Runtime: 14.36 seconds
  Mean Duration: 192.8 ± 86.5 seconds
  Onset Precision: 0.1714 ± 0.1131
  Onset Recall: 0.4042 ± 0.2335
  Onset F-measure: 0.1885 ± 0.0741
  Offset Precision: 0.2352 ± 0.1624
  Offset Recall: 0.4951 ± 0.2154
  Offset F-measure: 0.2509 ± 0.1006
  Average Overlap Ratio: 0.1497 ± 0.2015
  No-Offset Precision: 0.0231 ± 0.0177
  No-Offset Recall: 0.1046 ± 0.2094
  No-Offset F-measure: 0.0270 ± 0.0163
  Performance Range (F-measure): 0.0000 to 0.1345
  Efficiency (F-measure/runtime): 0.000157

RECONVAT:
  Files processed: 4751
  Mean F-measure: 0.1103 ± 0.0961
  Mean Precision: 0.1350 ± 0.0906
  Mean Recall: 0.1048 ± 0.1141
  Mean Runtime: 8.93 ± 9.62 seconds
  Median Runtime: 4.89 seconds
  Mean Duration: 171.2 ± 59.2 seconds
  Onset Precision: 0.6603 ± 0.1152
  Onset Recall: 0.4545 ± 0.2241
  Onset F-measure: 0.5065 ± 0.1672
  Offset Precision: 0.5813 ± 0.1039
  Offset Recall: 0.3831 ± 0.1600
  Offset F-measure: 0.4337 ± 0.1099
  Average Overlap Ratio: 0.8320 ± 0.0591
  No-Offset Precision: 0.5312 ± 0.1504
  No-Offset Recall: 0.3841 ± 0.2362
  No-Offset F-measure: 0.4199 ± 0.1915
  Performance Range (F-measure): 0.0000 to 0.6769
  Efficiency (F-measure/runtime): 0.013603

OMNIZART:
  Files processed: 1751
  Mean F-measure: 0.2645 ± 0.1251
  Mean Precision: 0.2764 ± 0.1281
  Mean Recall: 0.2588 ± 0.1291
  Mean Runtime: 31.13 ± 14.43 seconds
  Median Runtime: 31.26 seconds
  Mean Duration: 201.0 ± 87.0 seconds
  Onset Precision: 0.7642 ± 0.1633
  Onset Recall: 0.7039 ± 0.1479
  Onset F-measure: 0.7257 ± 0.1409
  Offset Precision: 0.6014 ± 0.1280
  Offset Recall: 0.5495 ± 0.0987
  Offset F-measure: 0.5691 ± 0.1049
  Average Overlap Ratio: 0.8471 ± 0.0366
  No-Offset Precision: 0.7483 ± 0.1696
  No-Offset Recall: 0.6893 ± 0.1542
  No-Offset F-measure: 0.7107 ± 0.1484
  Performance Range (F-measure): 0.0245 to 0.8462
  Efficiency (F-measure/runtime): 0.010141

MADMOM:
  Files processed: 1751
  Mean F-measure: 0.6379 ± 0.2894
  Mean Precision: 0.6727 ± 0.2842
  Mean Recall: 0.6106 ± 0.2962
  Mean Runtime: 67.92 ± 30.49 seconds
  Median Runtime: 74.63 seconds
  Mean Duration: 201.0 ± 87.0 seconds
  Onset Precision: 0.9866 ± 0.0192
  Onset Recall: 0.8716 ± 0.1017
  Onset F-measure: 0.9222 ± 0.0622
  Offset Precision: 0.8096 ± 0.1647
  Offset Recall: 0.7241 ± 0.2027
  Offset F-measure: 0.7617 ± 0.1833
  Average Overlap Ratio: 0.8953 ± 0.0273
  No-Offset Precision: 0.9757 ± 0.0273
  No-Offset Recall: 0.8627 ± 0.1077
  No-Offset F-measure: 0.9125 ± 0.0696
  Performance Range (F-measure): 0.0786 to 1.0000
  Efficiency (F-measure/runtime): 0.018990

------------------------------------------------------------
OVERALL CORRELATIONS (All Models Combined)
------------------------------------------------------------
Duration vs F-measure: -0.0737
Duration vs Precision: -0.0848
Duration vs Recall: -0.0722
Duration vs Runtime: 0.0619
Precision vs Recall: 0.9751
F-measure vs Overlap Ratio: 0.5319
F-measure vs No-Offset F-measure: 0.8075
Onset vs Offset Precision: 0.8130
Onset vs Offset Recall: 0.7694
Onset vs Offset F-measure: 0.8220
Runtime vs F-measure: 0.0811
Runtime vs Precision: 0.0670
Runtime vs Recall: 0.0897
Overlap Ratio vs Precision: 0.5465
Overlap Ratio vs Recall: 0.5252

------------------------------------------------------------
MODEL-SPECIFIC CORRELATIONS
------------------------------------------------------------

MT3 Correlations:
  Duration vs F-measure: -0.0569
  Precision vs Recall: 0.9719
  F-measure vs Overlap: -0.1394
  Onset vs Offset F-measure: 0.2900
  Runtime vs F-measure: 0.4829
  Runtime vs Duration: 0.1847

TRANSKUN Correlations:
  Duration vs F-measure: -0.4474
  Precision vs Recall: 0.9929
  F-measure vs Overlap: 0.3708
  Onset vs Offset F-measure: 0.2269
  Runtime vs F-measure: -0.2834
  Runtime vs Duration: 0.4059

BYTEDANCE_PIANO_TRANSCRIPTION Correlations:
  Duration vs F-measure: -0.4278
  Precision vs Recall: 0.9640
  F-measure vs Overlap: 0.6640
  Onset vs Offset F-measure: 0.4176
  Runtime vs F-measure: -0.4947
  Runtime vs Duration: 0.6103

BASIC_PITCH Correlations:
  Duration vs F-measure: -0.0882
  Precision vs Recall: 0.8509
  F-measure vs Overlap: 0.1037
  Onset vs Offset F-measure: 0.3716
  Runtime vs F-measure: 0.5124
  Runtime vs Duration: 0.2384

MR-MT3 Correlations:
  Duration vs F-measure: -0.0017
  Precision vs Recall: 0.9396
  F-measure vs Overlap: 0.5117
  Onset vs Offset F-measure: 0.1241
  Runtime vs F-measure: 0.0088
  Runtime vs Duration: -0.1624

CREPE_PITCH_TRACKER Correlations:
  Duration vs F-measure: 0.1162
  Precision vs Recall: 0.3744
  F-measure vs Overlap: 0.3621
  Onset vs Offset F-measure: 0.8377
  Runtime vs F-measure: 0.0505
  Runtime vs Duration: 0.0091

RECONVAT Correlations:
  Duration vs F-measure: -0.0283
  Precision vs Recall: 0.8080
  F-measure vs Overlap: -0.1561
  Onset vs Offset F-measure: 0.7454
  Runtime vs F-measure: 0.5214
  Runtime vs Duration: 0.1680

OMNIZART Correlations:
  Duration vs F-measure: -0.5379
  Precision vs Recall: 0.9033
  F-measure vs Overlap: 0.0054
  Onset vs Offset F-measure: 0.1253
  Runtime vs F-measure: -0.2926
  Runtime vs Duration: 0.5175

MADMOM Correlations:
  Duration vs F-measure: -0.4943
  Precision vs Recall: 0.9736
  F-measure vs Overlap: 0.4068
  Onset vs Offset F-measure: 0.7456
  Runtime vs F-measure: -0.5128
  Runtime vs Duration: 0.9768

------------------------------------------------------------
DATASET PERFORMANCE BREAKDOWN
------------------------------------------------------------

AAM:
  Total files: 12000
  Mean F-measure: 0.1204 ± 0.1128
  Mean Duration: 153.8 ± 17.7 seconds
  Mean Runtime: 14.42 ± 14.63 seconds
    MT3: 3000 files, F-measure: 0.2357
    Basic_Pitch: 3000 files, F-measure: 0.1785
    CREPE_Pitch_Tracker: 3000 files, F-measure: 0.0000
    ReconVAT: 3000 files, F-measure: 0.0674

BiMMuDa:
  Total files: 3375
  Mean F-measure: 0.5150 ± 0.3927
  Mean Duration: 200.7 ± 53.6 seconds
  Mean Runtime: 86.86 ± 66.79 seconds
    MT3: 375 files, F-measure: 0.9770
    Transkun: 375 files, F-measure: 0.7013
    Bytedance_Piano_transcription: 375 files, F-measure: 0.9676
    Basic_Pitch: 375 files, F-measure: 0.4359
    MR-MT3: 375 files, F-measure: 0.0032
    CREPE_Pitch_Tracker: 375 files, F-measure: 0.0020
    ReconVAT: 375 files, F-measure: 0.3089
    Omnizart: 375 files, F-measure: 0.2439
    Madmom: 375 files, F-measure: 0.9949

MSMD:
  Total files: 4203
  Mean F-measure: 0.4811 ± 0.3462
  Mean Duration: 106.7 ± 95.3 seconds
  Mean Runtime: 68.37 ± 120.66 seconds
    MT3: 467 files, F-measure: 0.8656
    Transkun: 467 files, F-measure: 0.7753
    Bytedance_Piano_transcription: 467 files, F-measure: 0.7443
    Basic_Pitch: 467 files, F-measure: 0.4563
    MR-MT3: 467 files, F-measure: 0.0027
    CREPE_Pitch_Tracker: 467 files, F-measure: 0.0068
    ReconVAT: 467 files, F-measure: 0.2342
    Omnizart: 467 files, F-measure: 0.4019
    Madmom: 467 files, F-measure: 0.8425

POP909:
  Total files: 7272
  Mean F-measure: 0.2648 ± 0.1919
  Mean Duration: 249.6 ± 42.3 seconds
  Mean Runtime: 42.71 ± 27.03 seconds
    MT3: 909 files, F-measure: 0.3542
    Transkun: 909 files, F-measure: 0.5368
    Bytedance_Piano_transcription: 909 files, F-measure: 0.3155
    Basic_Pitch: 909 files, F-measure: 0.2149
    CREPE_Pitch_Tracker: 909 files, F-measure: 0.0028
    ReconVAT: 909 files, F-measure: 0.1061
    Omnizart: 909 files, F-measure: 0.2025
    Madmom: 909 files, F-measure: 0.3856

Slakh 2100 Redux:
  Total files: 1710
  Mean F-measure: 0.0070 ± 0.0083
  Mean Duration: 252.7 ± 116.7 seconds
  Mean Runtime: 15.08 ± 2.76 seconds
    CREPE_Pitch_Tracker: 1710 files, F-measure: 0.0070

------------------------------------------------------------
PERFORMANCE RANKINGS
------------------------------------------------------------

F MEASURE Rankings:
  1. Madmom: 0.6379
  2. Transkun: 0.6356
  3. Bytedance_Piano_transcription: 0.5695
  4. MT3: 0.3788
  5. Omnizart: 0.2645
  6. Basic_Pitch: 0.2331
  7. ReconVAT: 0.1103
  8. MR-MT3: 0.0029
  9. CREPE_Pitch_Tracker: 0.0029

PRECISION Rankings:
  1. Madmom: 0.6727
  2. Transkun: 0.6410
  3. Bytedance_Piano_transcription: 0.5887
  4. MT3: 0.3807
  5. Omnizart: 0.2764
  6. Basic_Pitch: 0.2481
  7. ReconVAT: 0.1350
  8. CREPE_Pitch_Tracker: 0.0032
  9. MR-MT3: 0.0028

RECALL Rankings:
  1. Transkun: 0.6309
  2. Madmom: 0.6106
  3. Bytedance_Piano_transcription: 0.5585
  4. MT3: 0.3845
  5. Omnizart: 0.2588
  6. Basic_Pitch: 0.2325
  7. ReconVAT: 0.1048
  8. CREPE_Pitch_Tracker: 0.0059
  9. MR-MT3: 0.0033

ONSET F MEASURE Rankings:
  1. Transkun: 0.9847
  2. Bytedance_Piano_transcription: 0.9541
  3. Madmom: 0.9222
  4. MT3: 0.8857
  5. Omnizart: 0.7257
  6. Basic_Pitch: 0.7082
  7. ReconVAT: 0.5065
  8. CREPE_Pitch_Tracker: 0.1885
  9. MR-MT3: 0.0517

OFFSET F MEASURE Rankings:
  1. Madmom: 0.7617
  2. Transkun: 0.7362
  3. MT3: 0.7339
  4. Bytedance_Piano_transcription: 0.7140
  5. Basic_Pitch: 0.6011
  6. Omnizart: 0.5691
  7. MR-MT3: 0.5142
  8. ReconVAT: 0.4337
  9. CREPE_Pitch_Tracker: 0.2509

AVERAGE OVERLAP RATIO Rankings:
  1. MT3: 0.9506
  2. Bytedance_Piano_transcription: 0.9378
  3. Transkun: 0.9276
  4. Basic_Pitch: 0.8961
  5. Madmom: 0.8953
  6. Omnizart: 0.8471
  7. ReconVAT: 0.8320
  8. MR-MT3: 0.3571
  9. CREPE_Pitch_Tracker: 0.1497

------------------------------------------------------------
EFFICIENCY ANALYSIS
------------------------------------------------------------
Runtime Efficiency Rankings (F-measure per second):
  1. Madmom: 0.018990 F-measure/sec (1.1394 F-measure/min)
  2. Transkun: 0.015081 F-measure/sec (0.9049 F-measure/min)
  3. Basic_Pitch: 0.014960 F-measure/sec (0.8976 F-measure/min)
  4. Bytedance_Piano_transcription: 0.014539 F-measure/sec (0.8723 F-measure/min)
  5. ReconVAT: 0.013603 F-measure/sec (0.8162 F-measure/min)
  6. MT3: 0.012325 F-measure/sec (0.7395 F-measure/min)
  7. Omnizart: 0.010141 F-measure/sec (0.6085 F-measure/min)
  8. CREPE_Pitch_Tracker: 0.000157 F-measure/sec (0.0094 F-measure/min)
  9. MR-MT3: 0.000016 F-measure/sec (0.0009 F-measure/min)

------------------------------------------------------------
STATISTICAL SIGNIFICANCE TESTS
------------------------------------------------------------
ANOVA F-statistic for F-measure differences: 5312.9542
ANOVA p-value: 0.000000
Significant difference between models: Yes

Pairwise t-tests between models (F-measure):
  MT3 vs Transkun: t=-36.1476, p=0.000000
  MT3 vs Bytedance_Piano_transcription: t=-23.9125, p=0.000000
  MT3 vs Basic_Pitch: t=32.7670, p=0.000000
  MT3 vs MR-MT3: t=39.4743, p=0.000000
  MT3 vs CREPE_Pitch_Tracker: t=109.3279, p=0.000000
  MT3 vs ReconVAT: t=63.2762, p=0.000000
  MT3 vs Omnizart: t=16.6880, p=0.000000
  MT3 vs Madmom: t=-33.1134, p=0.000000
  Transkun vs Bytedance_Piano_transcription: t=7.7392, p=0.000000
  Transkun vs Basic_Pitch: t=97.7957, p=0.000000
  Transkun vs MR-MT3: t=101.5842, p=0.000000
  Transkun vs CREPE_Pitch_Tracker: t=280.7348, p=0.000000
  Transkun vs ReconVAT: t=150.7364, p=0.000000
  Transkun vs Omnizart: t=70.6649, p=0.000000
  Transkun vs Madmom: t=-0.2818, p=0.778081
  Bytedance_Piano_transcription vs Basic_Pitch: t=61.3470, p=0.000000
  Bytedance_Piano_transcription vs MR-MT3: t=53.3169, p=0.000000
  Bytedance_Piano_transcription vs CREPE_Pitch_Tracker: t=147.6093, p=0.000000
  Bytedance_Piano_transcription vs ReconVAT: t=91.3398, p=0.000000
  Bytedance_Piano_transcription vs Omnizart: t=38.3568, p=0.000000
  Bytedance_Piano_transcription vs Madmom: t=-6.7678, p=0.000000
  Basic_Pitch vs MR-MT3: t=50.2842, p=0.000000
  Basic_Pitch vs CREPE_Pitch_Tracker: t=139.0829, p=0.000000
  Basic_Pitch vs ReconVAT: t=51.6412, p=0.000000
  Basic_Pitch vs Omnizart: t=-8.6040, p=0.000000
  Basic_Pitch vs Madmom: t=-76.9241, p=0.000000
  MR-MT3 vs CREPE_Pitch_Tracker: t=0.2387, p=0.811334
  MR-MT3 vs ReconVAT: t=-32.3944, p=0.000000
  MR-MT3 vs Omnizart: t=-60.6747, p=0.000000
  MR-MT3 vs Madmom: t=-63.6589, p=0.000000
  CREPE_Pitch_Tracker vs ReconVAT: t=-89.4775, p=0.000000
  CREPE_Pitch_Tracker vs Omnizart: t=-167.2098, p=0.000000
  CREPE_Pitch_Tracker vs Madmom: t=-176.2172, p=0.000000
  ReconVAT vs Omnizart: t=-52.7038, p=0.000000
  ReconVAT vs Madmom: t=-110.2601, p=0.000000
  Omnizart vs Madmom: t=-49.5581, p=0.000000

------------------------------------------------------------
COMPLETE CORRELATION MATRIX
------------------------------------------------------------

Correlation Matrix (only values > 0.3 or < -0.3):
  precision vs recall: 0.9751
  precision vs f_measure: 0.9912
  precision vs average_overlap_ratio: 0.5465
  precision vs precision_no_offset: 0.7898
  precision vs recall_no_offset: 0.7415
  precision vs f_measure_no_offset: 0.7952
  precision vs average_overlap_ratio_no_offset: 0.8294
  precision vs onset_precision: 0.7166
  precision vs onset_recall: 0.6266
  precision vs onset_f_measure: 0.7430
  precision vs offset_precision: 0.7256
  precision vs offset_recall: 0.5744
  precision vs offset_f_measure: 0.7954
  recall vs f_measure: 0.9948
  recall vs average_overlap_ratio: 0.5252
  recall vs precision_no_offset: 0.7538
  recall vs recall_no_offset: 0.7886
  recall vs f_measure_no_offset: 0.8050
  recall vs average_overlap_ratio_no_offset: 0.8035
  recall vs onset_precision: 0.6646
  recall vs onset_recall: 0.7004
  recall vs onset_f_measure: 0.7563
  recall vs offset_precision: 0.6577
  recall vs offset_recall: 0.6647
  recall vs offset_f_measure: 0.8088
  f_measure vs average_overlap_ratio: 0.5319
  f_measure vs precision_no_offset: 0.7736
  f_measure vs recall_no_offset: 0.7725
  f_measure vs f_measure_no_offset: 0.8075
  f_measure vs average_overlap_ratio_no_offset: 0.8155
  f_measure vs onset_precision: 0.6899
  f_measure vs onset_recall: 0.6734
  f_measure vs onset_f_measure: 0.7576
  f_measure vs offset_precision: 0.6885
  f_measure vs offset_recall: 0.6309
  f_measure vs offset_f_measure: 0.8106
  average_overlap_ratio vs precision_no_offset: 0.7846
  average_overlap_ratio vs recall_no_offset: 0.6651
  average_overlap_ratio vs f_measure_no_offset: 0.7479
  average_overlap_ratio vs average_overlap_ratio_no_offset: 0.8253
  average_overlap_ratio vs onset_precision: 0.8466
  average_overlap_ratio vs onset_recall: 0.5513
  average_overlap_ratio vs onset_f_measure: 0.7891
  average_overlap_ratio vs offset_precision: 0.7453
  average_overlap_ratio vs offset_f_measure: 0.6908
  precision_no_offset vs recall_no_offset: 0.8755
  precision_no_offset vs f_measure_no_offset: 0.9699
  precision_no_offset vs average_overlap_ratio_no_offset: 0.8578
  precision_no_offset vs onset_precision: 0.9434
  precision_no_offset vs onset_recall: 0.7110
  precision_no_offset vs onset_f_measure: 0.9217
  precision_no_offset vs offset_precision: 0.7088
  precision_no_offset vs offset_recall: 0.3426
  precision_no_offset vs offset_f_measure: 0.7171
  recall_no_offset vs f_measure_no_offset: 0.9455
  recall_no_offset vs average_overlap_ratio_no_offset: 0.7594
  recall_no_offset vs onset_precision: 0.7662
  recall_no_offset vs onset_recall: 0.9125
  recall_no_offset vs onset_f_measure: 0.8913
  recall_no_offset vs offset_precision: 0.5000
  recall_no_offset vs offset_recall: 0.6225
  recall_no_offset vs offset_f_measure: 0.6866
  f_measure_no_offset vs average_overlap_ratio_no_offset: 0.8386
  f_measure_no_offset vs onset_precision: 0.8905
  f_measure_no_offset vs onset_recall: 0.8201
  f_measure_no_offset vs onset_f_measure: 0.9586
  f_measure_no_offset vs offset_precision: 0.6418
  f_measure_no_offset vs offset_recall: 0.4813
  f_measure_no_offset vs offset_f_measure: 0.7628
  average_overlap_ratio_no_offset vs onset_precision: 0.8327
  average_overlap_ratio_no_offset vs onset_recall: 0.6044
  average_overlap_ratio_no_offset vs onset_f_measure: 0.8111
  average_overlap_ratio_no_offset vs offset_precision: 0.7731
  average_overlap_ratio_no_offset vs offset_recall: 0.4044
  average_overlap_ratio_no_offset vs offset_f_measure: 0.7758
  onset_precision vs onset_recall: 0.6419
  onset_precision vs onset_f_measure: 0.9254
  onset_precision vs offset_precision: 0.8130
  onset_precision vs offset_f_measure: 0.7467
  onset_recall vs onset_f_measure: 0.8396
  onset_recall vs offset_precision: 0.3454
  onset_recall vs offset_recall: 0.7694
  onset_recall vs offset_f_measure: 0.6277
  onset_f_measure vs offset_precision: 0.6918
  onset_f_measure vs offset_recall: 0.5013
  onset_f_measure vs offset_f_measure: 0.8220
  offset_precision vs offset_f_measure: 0.8614
  offset_recall vs offset_f_measure: 0.6508

------------------------------------------------------------
FIGURES SAVED
------------------------------------------------------------
1. figures/01_core_performance_analysis.png - Main performance comparisons
2. figures/02_onset_offset_analysis.png - Onset/offset detailed analysis
3. figures/03_advanced_performance_patterns.png - Advanced pattern analysis
4. figures/04_statistical_summary.png - Statistical summary and rankings

================================================================================
ANALYSIS COMPLETE!
================================================================================
